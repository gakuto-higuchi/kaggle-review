# Open Problems – Multimodal Single-Cell Integrationの振り返り
---
## 解法と工夫した点
---
- 特徴量選択と次元削減：入力データが膨大だったため、22050の特徴量をSVDを使用して64次元に削減
  - よってデータの処理速度とモデルの計算効率上昇
- GroupKFold
  - ドナー(4人)ごとにGKFを使用し、ドナー間のばらつきにロバストなモデルを構築した
    - PublicTestDataではドナーの4番の方だけを予測するが、PrivateTestDataではドナーの1から4番に対して予測するため
- 損失関数の変更
  - このコンペではピアソン相関関数が推奨されていたが、異なる損失関数をいくつか試し、特にMSEが良い結果を示し、最終的なモデルにMSEを採用
- モデル選定
  - DNN:1DCNNが良かった。GBDTはensemble用に作成
- アンサンブル
  - 最終的には公開ノートブックの予測も含めて加重平均でアンサンブル
### 気をつけたこと
- publicとprivateでtest dataが異なるため、publicよりに学習しすぎないようにローカルCVスコアをpublicスコアよりも重視した
- パブリックスコアが良くても、プライベートスコアで順位が落ちるチームも多く見受けられた

## 上位解法を踏まえた結果に対する考察
---
上位陣はraw dataという途中で追加されたデータを追加して学習していたため、上位と大きく差が開いた原因がある。
多くのチームがロバスト性を高めるため、ドナーでGroupKFoldをしていたため、チームの方針は間違っていなかった。
上位では複雑なモデルが多く、DNNが多く採用されていた印象。データ数と特徴量が膨大だったため、DNNでの表現力が精度に寄与したのか？
データ変換ではノイズ除去は意味がないことが多く、元データのPCAとtSVDだけを使用したチームが多かった。

上位入賞者たちは、途中で追加された「raw data」を活用してモデルを学習させていた。これが私たちとの成績の大きな差となった主要な要因である可能性がある。多くのチームはロバスト性を高めるためにドナー毎にGroupKFoldを用いており、私たちの方針が間違っていなかったことを示している。
上位入賞者の中には複雑なモデルを採用しているケースが多く見受けられた。特に、データ量と特徴量の多さを考慮すると、DNNが採用されることが多かった。これは、DNNの高い表現力が精度向上に寄与したのではないかと推測される。
また、データ変換に関しては、ノイズ除去があまり意味をなさないケースが多かった。そのため、多くのチームは元のデータに対してPCAやtSVDを使用していることが多かった。これらの手法は、データの本質的な情報を保ちつつ次元削減を行うため、効果的であったと考えられる。

## 自身の貢献内容
---
コンペのタスクとしてmlutiomeとciteqの二つを予測するものであったため、citeqの予測モデル実装の担当になった。
具体的には、最適な次元削減方法の発見やモデルのパラメータチューニング、ロバスト性を担保するためのさまざまなクロスバリデーションを考えて構築しました。




